# Configuration for the Spark Reddit Sentiment Analysis Pipeline

# Kafka Configuration (Required by the Spark PipelineConfig model)
kafka:
  # List of Kafka broker addresses
  bootstrap_servers:
    - "kafka:9092" # Example: Use your actual Kafka broker address(es)
    # - "kafka2:9092"
    # - "kafka3:9092"

  # Kafka Topic Names (Ensure these match your actual topic names)
  topics:
    # Input topics (raw data - needed by KafkaConfig model, though script reads validated)
    social_media_reddit_posts: "social-media-reddit-posts-raw"
    social_media_reddit_comments: "social-media-reddit-comments-raw"
    social_media_reddit_symbols: "social-media-reddit-symbols-raw" # Not read by this script

    # Input topics (validated data - THESE ARE READ by the script)
    social_media_reddit_validated: "social-media-reddit-validated"
    social_media_reddit_comments_validated: "social-media-reddit-comments-validated"
    # social_media_reddit_symbols_validated: "social-media-reddit-symbols-validated" # Not read by this script

    # Output topics (validation output - needed by KafkaConfig model, not used by this script)
    social_media_reddit_invalid: "social-media-reddit-invalid"
    social_media_reddit_error: "social-media-reddit-error"

    # Other topics (needed by KafkaConfig model, not used by this script)
    social_media_reddit_rising_historical: "social-media-reddit-rising-historical"
    market_data_raw: "market-data-raw"
    market_data_validated: "market-data-validated"
    market_data_error: "market-data-error"
    sentiment_aggregated: "sentiment-aggregated-output" # Note: This script writes to Cassandra, not this topic

  # Consumer Groups (Required by KafkaConfig model, not directly used by Spark reader)
  consumer_groups:
    reddit_validation: "reddit-validation-group"
    reddit_comments_validation: "reddit-comments-validation-group"
    # Add other groups if defined/needed by the model

  # Generic Kafka Client Config (Required by KafkaConfig model)
  config:
    # Example: Add any global Kafka client settings if needed
    # security.protocol: "SASL_SSL"
    # sasl.mechanisms: "PLAIN"
    # sasl.username: "user"
    # sasl.password: "password"
    {} # Keep empty if no global settings needed

  # Kafka Producer Config (Required by KafkaConfig model, not used by this script)
  producer:
    acks: 1
    # linger.ms: 5
    # batch.size: 16384
    {} # Keep empty or add producer defaults if needed elsewhere

  # Kafka Consumer Config (Required by KafkaConfig model, not directly used by Spark reader)
  consumer:
    auto.offset.reset: "earliest"
    enable.auto.commit: true
    # session.timeout.ms: 10000
    # max.poll.interval.ms: 300000
    {} # Keep empty or add consumer defaults if needed elsewhere

  # Kafka Connect Config (Required by KafkaConfig model, not used by this script)
  connect:
    # Example Connect settings if needed by model
    # rest.port: 8083
    {}

# Cassandra Configuration
cassandra:
  keyspace: "marketpulse" # Target Cassandra keyspace
  table: "reddit_sentiment_aggregate" # Target Cassandra table
  connection_host: "cassandra" # Cassandra node hostname or IP address (or comma-separated list: "node1,node2")

# Spark Application Settings
spark_settings:
  app_name: "RedditSentimentAnalysis" # Name for the Spark application
  log_level: "INFO" # Spark log level (ERROR, WARN, INFO, DEBUG)

  # Spark Streaming Settings
  processing_window_duration: "5 minutes" # Duration for tumbling window aggregation (e.g., "1 minute", "10 minutes")
  watermark_delay_threshold: "10 minutes" # How long to wait for late data before finalizing window

  # Checkpointing Configuration
  # IMPORTANT: Use a persistent, fault-tolerant filesystem path (HDFS, S3, Azure Blob, persistent volume)
  # This path is the BASE directory; unique subdirectories will be created per run.
  checkpoint_location_base_path: "/opt/bitnami/spark/checkpoints/reddit_sentiment" # Example using local path within container (adjust if needed)
  # Example for HDFS: "hdfs://namenode:8020/spark_checkpoints/marketpulse"
  # Example for S3: "s3a://your-bucket/spark_checkpoints/marketpulse"


  # --- Optional Settings ---

  # Spark Package Versions (Uncomment and adjust if you want to control versions via config)
  # spark_cassandra_package: "com.datastax.spark:spark-cassandra-connector_2.12:3.4.1"
  # spark_kafka_package: "org.apache.spark:spark-sql-kafka-0-10_2.12:3.4.1"

  # Cassandra Write Consistency (Uncomment to override default 'LOCAL_QUORUM')
  # cassandra_write_consistency: "ONE" # Options: ANY, ONE, TWO, THREE, QUORUM, LOCAL_QUORUM, EACH_QUORUM, LOCAL_ONE, ALL 